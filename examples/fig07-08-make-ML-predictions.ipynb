{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aae5b99-4a7a-4a19-abc7-8ce355879d51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook for making predictions with an ensemble of SuperLearner machine learning models.\n",
    "\n",
    "This Jupyter notebook is an example for how to reuse an archived ML model trained for predicting sediment respiration rates. The general concepts used here can be applied elsewhere. The core operations used here are based on `sl_core/predict.py` available at [this link](https://github.com/parallelworks/sl_core/blob/main/predict.py).\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "In order to use the ML model, you need to first get access to the Python packages necessary for running the model. SuperLearners are currently stored in `.pkl` format and this format is sensitive to the exact versions of Python and scikit-learn that are in the active environment. (Future work will move SuperLearners to ONNX format which is more portable.) The SuperLearner automatically stores `.yaml` files that define its run environment, but, to keep environments lightweight and minimize install time, etc., these environments do not contain the packages needed for displaying Jupyter notebooks. As such, this repository contains a `.yaml` that can be used with the following command:\n",
    "```\n",
    "conda env update --name <your-env-name> -f fig07-08-notebook-conda-env.yaml\n",
    "```\n",
    "\n",
    "This file was created from an automatically generated SuperLearner environment definition file with the following commands:\n",
    "```\n",
    "conda create -y --name superlearner python=3.9\n",
    "conda activate superlearner\n",
    "conda env update --name superlearner -f requirements.yaml\n",
    "conda install -y -c conda-forge requests\n",
    "conda install -y -c anaconda jinja2\n",
    "conda install -y -c conda-forge ipykernel\n",
    "conda env export --name superlearner > fig07-08-notebook-conda-env.yaml\n",
    "```\n",
    "\n",
    "The `.yaml` files here are stored as gzipped files `.yaml.gz` because otherwise GitHub will read the `requirements.yaml` files and print security warnings if the files use out of date packages. Since this code is of limited duration scientific use (i.e. not production) I have ignored these warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaeeaffa-3e4d-4ff0-b589-308016336649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a711c498-f0cd-4f3b-8490-8be56b787872",
   "metadata": {},
   "source": [
    "## Specify repository and branch to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34274d4e-7e95-441b-95c3-5f82cdfa56ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sl-archive-whondrs' already exists and is not an empty directory.\n",
      "M\tml_models/sl_0/requirements.yaml.gz\n",
      "Already on 'S19S-SSS-log10-extrap-r02'\n"
     ]
    }
   ],
   "source": [
    "# Using ~ here for $HOME will cause pickle.load failures later\n",
    "# so must use absolute path.\n",
    "repo_prefix = '/home/sfgary/tmp/'\n",
    "repo_name = 'sl-archive-whondrs'\n",
    "repo_url = 'https://github.com/parallelworks/'+repo_name\n",
    "branch = 'S19S-SSS-log10-extrap-r02'\n",
    "\n",
    "# Grab the data and get onto the branch if not already there\n",
    "! mkdir -p {repo_prefix}\n",
    "! cd {repo_prefix}; git clone {repo_url}\n",
    "! cd {repo_prefix}/{repo_name}; git checkout {branch}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9eee97-6948-4a38-a14a-d782a15568f1",
   "metadata": {},
   "source": [
    "## Load data that will be used to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39a91caa-b403-488e-8a23-2826d9b763e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are two zipped files.  Decompress and load each one\n",
    "!gunzip -c grdb_step_03b_output_RiverATLAS_v10_na.xyz.7411.csv.gz > grdb_step_03b_output_RiverATLAS_v10_na.xyz.7411.csv\n",
    "!gunzip -c grdb_step_03b_output_RiverATLAS_v10_na.xyz.7412.csv.gz > grdb_step_03b_output_RiverATLAS_v10_na.xyz.7412.csv\n",
    "\n",
    "# Do not specify ID as the index when loading the data because\n",
    "# we will want to remove it later.\n",
    "list_df = []\n",
    "list_df.append(pd.read_csv('grdb_step_03b_output_RiverATLAS_v10_na.xyz.7411.csv')) #, index_col='RA_ID'))\n",
    "list_df.append(pd.read_csv('grdb_step_03b_output_RiverATLAS_v10_na.xyz.7412.csv')) #, index_col='RA_ID'))\n",
    "\n",
    "# Clean up\n",
    "!rm grdb_step_03b_output_RiverATLAS_v10_na.xyz.7411.csv\n",
    "!rm grdb_step_03b_output_RiverATLAS_v10_na.xyz.7412.csv\n",
    "\n",
    "# Concatenate\n",
    "predict_df = pd.concat(list_df,axis=0)\n",
    "\n",
    "# Some river segments are so short they only have one coordinate point.\n",
    "# Replace any missing (lon2,lat2) with (lon1,lat2) for uniformity.\n",
    "# Add a very very small displacement to each so all segments have\n",
    "# very small but non-zero length.\n",
    "predict_df['lon2'].fillna(value=predict_df['lon1']+0.000001,inplace=True)\n",
    "predict_df['lat2'].fillna(value=predict_df['lat1']+0.000001,inplace=True)\n",
    "\n",
    "# Store the ID, lon, and lat in a separate dataframe for integration later\n",
    "# These values are NOT used by the ML model and and such should be removed\n",
    "# from the DF that is going to be used to make predictions.\n",
    "predict_ixy = pd.DataFrame(columns=['RA_ID','lon1','lat1','lon2','lat2'])\n",
    "predict_ixy['RA_ID'] = predict_df.pop('RA_ID')\n",
    "predict_ixy['lon1'] = predict_df.pop('lon1')\n",
    "predict_ixy['lat1'] = predict_df.pop('lat1')\n",
    "predict_ixy['lon2'] = predict_df.pop('lon2')\n",
    "predict_ixy['lat2'] = predict_df.pop('lat2')\n",
    "\n",
    "# There is exactly one NaN value remaining at one site for the stream\n",
    "# depth. For generality with other data sets, replace any NaN\n",
    "# with the mean value of the whole column.\n",
    "predict_df.fillna(predict_df.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "570ab496-8abd-4d90-b44e-ee69c0a575de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on SuperLearner ensemble member 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on SuperLearner ensemble member 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on SuperLearner ensemble member 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sfgary/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 43.3 GiB for an array with shape (86054, 67525) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 29\u001b[0m\n\u001b[1;32m     19\u001b[0m predict_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormalized_Respiration_Rate_mg_DO_per_H_per_L_sediment\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(\"Submodels within SuperLearner and their weights:\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#list_models = list(superlearner[predict_var].named_estimators_.keys())\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(list_models)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m sl_predict_output_df_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43msuperlearner\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredict_var\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_df\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:369\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_estimator_\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:972\u001b[0m, in \u001b[0;36mStackingRegressor.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the predictions for X for each estimator.\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:293\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(est, meth)(X)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m ]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m ]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/compose/_target.py:295\u001b[0m, in \u001b[0;36mTransformedTargetRegressor.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the base regressor, applying inverse.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03mThe regressor is used to predict and the `inverse_func` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    Predicted values.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregressor_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    297\u001b[0m     pred_trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_\u001b[38;5;241m.\u001b[39minverse_transform(pred\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.miniconda3c/envs/superlearner/lib/python3.9/site-packages/sklearn/preprocessing/_polynomial.py:507\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    503\u001b[0m     XP \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mhstack(columns, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mtocsc()\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Do as if _min_degree = 0 and cut down array after the\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     XP \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_out_full\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# What follows is a faster implementation of:\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# for i, comb in enumerate(combinations):\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m#     XP[:, i] = X[:, comb].prod(1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m \n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# degree 0 term\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_bias:\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 43.3 GiB for an array with shape (86054, 67525) and data type float64"
     ]
    }
   ],
   "source": [
    "# Set number of SuperLearner ensemble members\n",
    "num_sl = 10\n",
    "\n",
    "# Initialize data frame list to hold output\n",
    "sl_predict_output_df_list = []\n",
    "\n",
    "# Loop over all ensemble members\n",
    "for ll in range(0,num_sl):\n",
    "    \n",
    "    print(\"Working on SuperLearner ensemble member \"+str(ll))\n",
    "    \n",
    "    # Load the SuperLearner model from .pkl\n",
    "    model_dir = repo_prefix+repo_name+\"/ml_models/sl_\"+str(ll)\n",
    "    sys.path.append(model_dir)\n",
    "    with open(model_dir+'/SuperLearners.pkl','rb') as file_object:\n",
    "        superlearner = pickle.load(file_object)\n",
    "\n",
    "    # OPTIONAL: For a given output variable, list the models:\n",
    "    predict_var = 'Normalized_Respiration_Rate_mg_DO_per_H_per_L_sediment'\n",
    "    #print(\"Submodels within SuperLearner and their weights:\")\n",
    "    #list_models = list(superlearner[predict_var].named_estimators_.keys())\n",
    "    #print(list_models)\n",
    "    \n",
    "    # OPTIONAL: The following only works for the scipy.optimize.nnls\n",
    "    # stacking regressor, not the sklearn stacking regressors.\n",
    "    #print(superlearner[predict_var].final_estimator_.weights_)\n",
    "    \n",
    "    # Make predictions\n",
    "    sl_predict_output_df_list.append(superlearner[predict_var].predict(predict_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283a68d-950e-4e51-a1f9-dc1e2f08c4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:superlearner]",
   "language": "python",
   "name": "conda-env-superlearner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
